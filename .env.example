# Optional: Fallback API key when Claude Code limits are hit
# ANTHROPIC_API_KEY=sk-ant-xxx

# Port to run the proxy on (default: 8082)
# PORT=8082

# Set to false to use direct API instead of Claude Code first
# CLAUDE_CODE_FIRST=true

# OpenAI/OpenRouter passthrough (for non-Claude models)
# OPENAI_API_KEY=sk-xxx
# OPENAI_BASE_URL=https://api.openai.com  # or https://openrouter.ai/api for OpenRouter

# OpenRouter-specific (optional)
# OPENROUTER_REFERER=https://your-app.com
# OPENROUTER_TITLE=YourApp

# IP whitelist for tunnel requests (comma-separated)
# Default: Cursor's backend IPs (52.44.113.131,184.73.225.134)
# Only enforced when requests come through Cloudflare tunnel (have CF-* headers)
# ALLOWED_IPS=52.44.113.131,184.73.225.134,3.209.66.12

# --- Compaction (Server-Side Context Management) ---

# Enable server-side compaction for Opus 4.6+ models (default: true)
# When enabled, the proxy injects a compact_20260112 edit that triggers Anthropic's
# server-side summarization when input tokens exceed the trigger threshold.
# This prevents 400 errors when OAuth's 200K context limit is reached.
# COMPACTION_ENABLED=true

# Token threshold to trigger compaction (default: 150000, minimum: 50000)
# When input tokens exceed this value, the API generates a compaction summary.
# Lower values = more frequent compaction, higher values = more context preserved.
# COMPACTION_TRIGGER_TOKENS=150000

# --- Token Inflation ---

# Enable token inflation for prompt_tokens reported to Cursor (default: false)
# Only needed when using MAX Mode ON (872K context denominator in Cursor).
# Inflates prompt_tokens by ~4.36x so Cursor's context bar fills proportionally to the real 200K limit.
# With MAX Mode OFF (200K denominator), this is NOT needed — raw tokens are already truthful.
# TOKEN_INFLATION=true

# --- Logging ---

# Verbose file logging — writes detailed request/response data to api.log (default: false)
# Console logging always works regardless of this setting
# VERBOSE_LOGGING=true
